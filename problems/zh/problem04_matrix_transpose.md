# 第 4 题：矩阵转置

在现代计算中，二维并行无处不在：图像处理中的每个像素操作、计算机图形学中的每个变换、科学仿真中的每个有限差分计算都依赖于二维并行处理。

CUDA 天然支持二维线程模型，让你可以按问题本身的二维结构来组织线程，而不必将二维问题“硬塞”到一维排列中。

## 🎯 本题学习目标

- 理解二维线程的组织与索引方式
- 熟悉二维网格（Grid）和线程块（Block）的配置策略
- 掌握矩阵在内存中的行主序布局及其访问规律
- 领会图形学与线性代数中，坐标变换的基本原理

## CUDA 的二维线程模型

CUDA 的二维线程模型允许你将线程组织成二维网格（Grid）和线程块（Block），这使得处理二维数据（如矩阵）变得更加直观。具体来说，每个 Grid 由多个 Block 组成，每个 Block 又包含多个线程，它们均以二维形式组织。

```
Grid:               Block B00:          Thread T00:
┌─────┬─────┐       ┌───┬───┬───┐       ┌─────────┐
│ B00 │ B01 │       │T00│T01│T02│       │ Thread  │
├─────┼─────┤       ├───┼───┼───┤       └─────────┘
│ B10 │ B11 │       │T10│T11│T12│
└─────┴─────┘       └───┴───┴───┘
```

可以通过以下内置变量定位每个线程：

* `blockIdx.x/y` 表示当前线程所在的 Block 的索引
* `threadIdx.x/y` 表示当前线程在 Block 内的索引

结合这些坐标和维度信息，即可算出每个线程在全局矩阵中的行列索引。

## 矩阵转置

矩阵转置沿对角线翻转矩阵，将行转换为列。

```
原始矩阵 A (3×4):            转置矩阵 B (4×3):
┌─────────────────┐         ┌─────────────┐
│  1   2   3   4  │         │  1   5   9  │
│  5   6   7   8  │   →     │  2   6  10  │
│  9  10  11  12  │         │  3   7  11  │
└─────────────────┘         │  4   8  12  │
                            └─────────────┘
```

它虽然概念直观，却能帮助你深入理解二维内存访问、坐标映射与布局转换。

## 行主序内存布局

计算机内存中的矩阵使用行主序作为1D数组存储。理解这种布局对高效 GPU 编程至关重要：

```
矩阵 A[3][4]:        内存布局:
┌─ 1  2  3  4 ─┐    [1][2][3][4][5][6][7][8][9][10][11][12]
├─ 5  6  7  8 ─┤    ↑   第0行    ↑   第1行    ↑    第2行    ↑
└─ 9 10 11 12 ─┘
```

元素 `A[row][col]` 的一维索引: row * num_cols + col

在转置的时候，索引 `i * K + j` 的元素 A[i][j] 会被写入到索引 `j * M + i` 的位置。

## 二维线程索引

host 端代码使用 `dim3` 来配置二维网格和线程块，传入 2 个参数代表第一维和第二维的大小。

我们使用 `n` 为矩阵的行数，`m` 为矩阵的列数。

```cpp
void transpose_matrix_host(const std::vector<int> &h_A, std::vector<int> &h_B, int n, int m) {
    // 内存分配和复制...
    
    dim3 threadsPerBlock(TILE_SIZE, TILE_SIZE);
    
    // 计算覆盖整个矩阵的2D网格大小
    dim3 numBlocks((m + threadsPerBlock.x - 1) / threadsPerBlock.x,
                   (n + threadsPerBlock.y - 1) / threadsPerBlock.y);
    
    transpose_kernel<<<numBlocks, threadsPerBlock>>>(d_A, d_B, n, m);
    
    // 复制回来并清理...
}
```

你可能注意到在设置 `dim3` 的大小的时候，第一维为列方向的大小，第二维为行方向的大小。这是因为 CUDA 的线程索引维度是从小到大排列的，在内存层面，第一维的元素是连续的。

在编写 kernel 函数的时候，也要记住 `blockIdx.x/threadIdx.x`（第一维）负责列方向，`blockIdx.y/threadIdx.y` （第二维）负责行方向。

```cpp
__global__ void transpose_kernel(const int* d_A, int* d_B, int n, int m) {
    // 计算坐标
    int col_A = blockIdx.x * blockDim.x + threadIdx.x;
    int row_A = blockIdx.y * blockDim.y + threadIdx.y;
    
    // 检查输入矩阵的边界
    if (row_A < n && col_A < m) {
        // 每个 thread 处理一个矩阵元素
    }
}
```

## 优化性能

全局内存有两种访问模式，合并（coalesced）和非合并（uncoalesced）。在一次数据传输中，从全局内存转移到 L2 缓存的一片内存的首地址一定是一个最小粒度的整数倍。如果相同线程块的线程访问连续的内存地址，那么就可以直接使用其他内存的缓存。

在转置操作中，读取矩阵 A 是顺序的。假设第一个线程访问了 A[0][0]，那么再读取内存的时候可能会将 A[0][0] - A[0][7] 一起加载到缓存中，这样第 2-8 个线程就可以直接从缓存中读取，实现了内存访问的合并。但写入矩阵 B 时是较为分散的，因为每个线程都在写入不同的行，每个线程之间的写入地址相隔较远，会导致非合并访问。

为了优化性能，可以使用共享内存来优化内存访问。其基本思路是每个线程块先将一个子矩阵加载到共享内存中，然后再从共享内存中转置并写回全局内存。保证在访问全局内存时相同线程块的线程尽可能地访问连续的内存地址。

具体实现可以参考 `answer.cu`。

## 总结

至此，你已掌握二维 CUDA 编程的基础：如何配置二维网格与线程块、计算全局二维坐标、执行边界检查并进行坐标变换。下一题我们将探讨并行归约（Parallel Reduction），探索如何在 CUDA 中高效地汇总结果。