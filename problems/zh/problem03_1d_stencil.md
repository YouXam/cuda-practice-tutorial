# 第 3 题：1d stencil - 使用共享内存

我们将探讨GPU编程中的关键概念：共享内存（Shared memory）和协作计算。你将通过实现一个1D平均滤波器，掌握如何利用共享内存显著提升程序性能。

## 🎯 本题学习目标

- Shared memory 和 GPU 内存层次结构
- 掌握线程协作与同步机制
- 实现一维 Stencil算 法优化

## GPU内存架构解析

GPU 包含多级内存结构，各自具有不同的特性：

**全局内存（Global Memory）**：所有线程均可访问的主存空间。它空间很大（GB 级别）但相对较慢，访问需要数百个时钟周期。

**共享内存（Shared Memory）**： 块内线程共享的高速内存。它很小（每个 block 几 KB）但非常快，只需几个时钟周期就能访问。

**寄存器（Register）**：线程私有存储，速度最快但数量有限。

共享内存的访问速度比全局内存快数百倍，合理利用可带来显著性能提升。

## 一维平均滤波器原理

Stencil 算法使用相邻元素计算输出值。在本实验中，每个输出元素为其自身与左右邻居的平均值：

以数组 `[4, 7, 2, 9, 1, 8, 3, 6]` 为例，第三个元素的输出为：

```
[4, 7, 2, 9, 1, 8, 3, 6]
    ^  ^  ^
(7 + 2 + 9) / 3 = 6
```

## 性能瓶颈分析

朴素实现方式中，每个线程需从全局内存多次读取数据：

```cpp
// 每个线程从低速全局内存读取3个值
C[idx] = (A[idx - 1] + A[idx] + A[idx + 1]) / 3;
```

处理元素 5 的线程读取 A[4]、A[5] 和 A[6]。处理元素 6 的线程读取 A[5]、A[6] 和 A[7]，它们都需要读取 A[5] 和 A[6]。导致大量冗余的全局内存访问，严重影响性能。

## 共享内存优化方案

我们可以采用以下的方法来优化这个问题：

1. 线程协作将数据块载入共享内存
2. 同步等待数据加载完成
3. 从高速共享内存读取数据计算结果

该方法将多次低速全局内存访问转换为单次加载加多次高速共享内存访问。

数据加载时，每个线程需要访问其左右相邻元素。例如，处理100-115元素的16线程块，实际需要加载99-116元素。额外的99和116元素被称为“halo”或“ghost”单元。

```
Global Memory: [... 99 100 101 102 ... 114 115 116 ...]
Shared Memory: [99][100 101 102 ... 114 115][116]
                ↑        ← 主数据区域 →         ↑
              左 halo                      右 halo
```

## 任务

请使用共享内存优化实现1D平均滤波器：

### 步骤1：声明共享内存

```cpp
__global__ void stencil1D_kernel(int* d_A, int* d_C, int N) {
    extern __shared__ int s_data[];  // 动态共享内存
    
    const int radius = 1;
    int tid = threadIdx.x;
    int gid = blockIdx.x * blockDim.x + threadIdx.x;
```

`extern __shared__` 声明创建块内线程共享的内存空间，大小在 kernel 函数启动时确定。

### 步骤2：协作数据加载

第一个线程和最后一个线程分别负责加载前后两个 halo 元素，其他元素由线程协作加载。

在加载 halo 元素的时候，需要额外注意处理边界情况，确保不会访问越界。我们采用"边缘钳制"方法：

- 对于第一个元素，左邻居 A[-1] 不存在，使用 A[0]。
- 对于最后一个元素，右邻居 A[N] 不存在，使用 A[N-1]。

### 步骤3：同步

```cpp
    __syncthreads();  // 等待所有线程完成加载
```

同步操作至关重要，确保所有数据就绪后再开始计算。`__syncthreads()` 调用创建一个屏障 - 确保所有线程到达同步点后再继续执行。

这里同步有两个目的：正确性（确保数据在使用前被加载）和性能（确保所有线程一起进行以获得最大效率）。

### 步骤4：共享内存计算

```cpp
    if (gid < N) {
        int left = s_data[tid + radius - 1];
        int center = s_data[tid + radius];
        int right = s_data[tid + radius + 1];
        
        d_C[gid] = (left + center + right) / 3;
    }
```

此时所有数据访问均在高速共享内存中完成。

## Host 端配置

kernel 中使用 `extern __shared__` 声明了动态共享内存，在调用 kernel 时需要指定共享内存的大小。

```cpp
int threadsPerBlock = 256;
int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;

// 计算共享内存大小
int radius = 1;
int sharedMemSize = (threadsPerBlock + 2 * radius) * sizeof(int);

// 启动核函数
stencil1D_kernel<<<blocksPerGrid, threadsPerBlock, sharedMemSize>>>(d_A, d_C, N);
```

动态共享内存的优势是可以根据问题规模灵活调整大小，而不需要在编译时固定。但本题中共享内存大小实际上是固定的，我们也可以使用静态共享内存声明：

```cpp
// 在 kernel 函数中使用静态共享内存
__shared__ int s_data[256 + 2];
```

静态共享内存不需要在调用时指定大小，启动核函数时传入两个参数即可。

## 性能提升分析

共享内存优化后，全局内存访问次数从"每线程三次"降为"每块单次"。对于 256 线程的块，理论可减少 256 倍全局内存流量。

## 总结

你现在理解了协作并行算法、线程同步和共享内存优化。这些技能适用于几乎每个高性能 GPU 算法。

在后续实验中，我们将把这些概念扩展到2D，其中对处理图像和矩阵变得更加强大。

恭喜你掌握了CUDA最强大的优化技术之一！