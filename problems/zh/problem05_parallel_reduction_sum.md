# 第 5 题：并行归约算法

欢迎来到并行计算中最优雅且重要的算法之一——并行归约！这种算法将原本需要顺序执行的多值组合任务，转变为高效的并行操作。这是你学习复杂线程协作模式的绝佳起点。

## 🎯 学习目标

- 掌握基于树结构的并行算法及其对数复杂度特性
- 学习高级线程协作与同步模式
- 实现GPU与CPU协同的多层次计算策略
- 理解并行计算中的基础归约模式

## 并行归约的核心思想

归约操作通过加法、求最大值或乘法等关联运算，将多个输入值合并为单个输出。传统顺序处理方法逐个处理元素，无法充分利用并行硬件的优势，而并行方法可以并行运行多个关联运算。以 1-8 一共 8 个数字求和为例：

```
顺序执行:
1+2=3 → 3+3=6 → 6+4=10 → 10+5=15 → 15+6=21 → 21+7=28 → 28+8=36
耗时：7步（与N成正比）

并行树归约:
第1轮: [1+2] [3+4] [5+6] [7+8] → [3] [7] [11] [15] (4个并行操作)
第2轮: [3+7] [11+15] → [10] [26] (2个并行操作)  
第3轮: [10+26] → [36] (1个操作)
耗时：3步（与log N成正比）
```

这种归约算法通过分层次的并行计算，将 N 个元素的归约操作从 O(N) 降低到 O(log N)，极大提升了效率。

## 任务：并行数组求和

你需要利用并行树归约算法，计算一个整数数组的总和。

## 树归约算法

树归约算法的精妙在于其简洁高效。以下展示8个线程在共享内存中的工作流程：

```
初始共享内存: [5] [3] [8] [1] [7] [2] [9] [4]
线程ID:       0   1   2   3   4   5   6   7

步长=4:
线程0-3分别累加4个位置后的元素:
  [5+7] [3+2] [8+9] [1+4] [ ] [ ] [ ] [ ]
→ [12]  [5]   [17]  [5]   [ ] [ ] [ ] [ ]

步长=2:  
线程0-1分别累加2个位置后的元素:
  [12+17] [5+5] [ ] [ ] [ ] [ ] [ ] [ ]
→ [29]    [10]  [ ] [ ] [ ] [ ] [ ] [ ]

步长=1:
线程0累加1个位置后的元素:
  [29+10] [ ] [ ] [ ] [ ] [ ] [ ] [ ]
→ [39]    [ ] [ ] [ ] [ ] [ ] [ ] [ ]
```

经过三轮计算后，线程 0 所在的共享内存位置存储了所有8个数值的总和。

### 步骤 1：Grid-Stride 加载

```cpp
__global__ void reduce_sum_kernel(int* d_A_global, int* d_block_sums, int N) {
    extern __shared__ int s_data[];
    
    int tid = threadIdx.x;
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    int stride = gridDim.x * blockDim.x;

    // 每个线程累加多个元素
    int temp_sum = 0;
    for (int i = idx; i < N; i += stride) {
        temp_sum += d_A_global[i];
    }
    s_data[tid] = temp_sum;
    
    __syncthreads();  // 确保归约前所有数据就位
```

kernel 使用动态共享内存存储归约数据。每个 block 通过 grid-stride 循环处理多个元素。

例如假设一共有 4 个线程，那么当处理 8 个元素时，第 0 个线程将会累加第 0, 4 个元素，第 1 个线程累加第 1, 5 个元素，以此类推。累加完毕之后再进行树状归约。

Grid-stride循环是GPU编程的经典模式。我们不需要启动 N 个线程，而是启动合理数量的block，让每个线程处理多个元素，从而提高GPU利用率。

### 步骤 2：树归约

```cpp
    // 执行树状归约
    for (int s = blockDim.x / 2; s > 0; s >>= 1) {
        if (tid < s) {
            s_data[tid] += s_data[tid + s];
        }
        __syncthreads();  // 同步点
    }
```

这是算法的核心部分。每次迭代中，步长减半，活跃线程累加特定步长位置的值。

同步操作至关重要。缺少同步会导致线程使用不一致的数据版本，造成计算结果错误。

### 步骤 3：存储 Block 结果

```cpp
    // 线程0存储block的部分和
    if (tid == 0) {
        d_block_sums[blockIdx.x] = s_data[0];
    }
```

归约完成后，每个block的线程 0 将部分和存入全局数组，供主机端进一步处理。

## 步骤 4: 将不同 Block 的结果归约

现在我们有了每个 block 的部分和，接下来需要将这些结果归约到一个最终结果。有三种方式可以实现这一点：

1. 在 CPU 上使用循环累加；
2. 在 kernel 中使用原子操作累加到一个变量中（原子操作会在后面的题目中介绍）；
3. 再次使用树状归约算法。

我们选择第三种方式，继续使用树状归约算法来处理这些 block 的部分和。分析前面三步，可以发现归约 kernel 运行的结果数量正是 block 的数量，所以只要指定 block 数量为 1 就可以将第一步归约的部分和再次归约到一个最终结果。

```cpp
reduce_sum_kernel<<<num_blocks, BLOCK_SIZE, shared_memory_size>>>(d_A_global, d_block_sums, N);
reduce_sum_kernel<<<1, BLOCK_SIZE, shared_memory_size>>>(d_block_sums, result, num_blocks);
```

## 总结

通过本题，你不仅学会了复杂的线程协作和屏障同步，还掌握了多层并行算法设计。这些技能能帮助你充分利用GPU和CPU的协同计算能力。

值得注意的是，归约模式不仅限于简单求和。相同的树结构可应用于求最大值、点积计算、收敛性判断等场景。

在接下来的第 6 题中，我们将把这些协作概念扩展到 2D 图像处理领域，探索线程如何高效处理空间邻域数据。